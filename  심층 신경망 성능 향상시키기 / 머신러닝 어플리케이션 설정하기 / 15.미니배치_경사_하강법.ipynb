{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Andrew_Ng_2_15.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNQTDT63891BRbxqpXzAShQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/audrb1999/ML-DL-Study/blob/main/%20%EC%8B%AC%EC%B8%B5%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%84%B1%EB%8A%A5%20%ED%96%A5%EC%83%81%EC%8B%9C%ED%82%A4%EA%B8%B0%20/%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EC%96%B4%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98%20%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0%20/%2015.%EB%AF%B8%EB%8B%88%EB%B0%B0%EC%B9%98_%EA%B2%BD%EC%82%AC_%ED%95%98%EA%B0%95%EB%B2%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYEjt2zPf-tf"
      },
      "source": [
        "# 미니 배치 경사 하강법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHYkJ7eNiEFH"
      },
      "source": [
        "이전에 벡터화가 m개의 샘플에 대한 계산을 효율적으로 만들어준다고 했습니다. \n",
        "\n",
        "- 반복문을 사용하지 않아서!\n",
        "\n",
        "훈련 샘플을 받으면 큰 행렬에 저장합니다.\n",
        "\n",
        "X = [$x^{[1]}, x^{[2]}, x^{[3]}, ... x^{[m]}$] \n",
        "\n",
        "> shpae = (n_x, m)\n",
        "\n",
        "- y도 비슷하게\n",
        "\n",
        "Y = [$y^{[1]}, y^{[2]}, y^{[3]}, ... y^{[m]}$]\n",
        "\n",
        "> shape = (1, m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UrNSLNliECn"
      },
      "source": [
        "벡터화는 m개의 샘플을 상대적으로 빠르게 훈련시킬 수 있지만 m이 매우 크다면 느릴 수 도있습니다.\n",
        "\n",
        "- m = 5,000,000이라면 경사 하강법 단계마다 오백만 개의 전체 훈련 샘플을 처리해야합니다!\n",
        "  - 비효율적!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORtO9twUiD__"
      },
      "source": [
        "그럼 오백만 개의 거대한 훈련 샘플을 모두 처리하기전에 경사 하강법을 진행해보면 어떨까?  > 더 빠른 알고리즘을 얻을 수 있음!\n",
        "  - 미니 배치!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IognNSd1iD9f"
      },
      "source": [
        "훈련 세트를 작게 나눠보자! --> 이런 작은 훈련세트는 미니배치라고 부름!\n",
        "\n",
        "오백만 개의 데이터를 1000개씩 나눠보자!\n",
        "\n",
        "여기서 나눠진 x데이터 집합을 $X^{\\{n\\}}$이라고 부릅니다.\n",
        "\n",
        "- $X^{\\{1\\}}$ = $[x^{[1]},.... x^{[1000]}]$ 까지\n",
        "\n",
        "- Y도 마찬가지!\n",
        "$Y^{\\{1\\}}$ = $[y^{[1]},.... y^{[1000]}]$\n",
        "\n",
        "- mini-batch t= $X^{\\{t\\}}$, $Y^{\\{t\\}}$\n",
        "  - t = 미니 배치의 갯수\n",
        "\n",
        "\n",
        "> [] = 몇 번째 레이어인지  \n",
        " () = 몇 번째 데이터인지  \n",
        "  {} = 몇 번째 미니 배치인지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI0f4gouiD7H"
      },
      "source": [
        "배치 경사 하강법 = 모든 데이터에 대해 경사 하강법을 진행\n",
        "\n",
        "미니 배치 경사 하강법 = 미니 배치에 대해 경사 하강법을 진행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M45F3tU2iD4v"
      },
      "source": [
        "1번째 미니 배치로 경사하강법 구현\n",
        "\n",
        "for문을 통한 1000번 반복이 아닌 벡터화를 사용해 모든 1000개의 샘플을 동시에 진행!\n",
        "\n",
        "\n",
        "비용함수 J를 계산해보겠습니다.\n",
        "\n",
        "$J^{\\{t\\}} = \\frac 1 {1000} \\Sigma L( y^{pred[i]} - y^{true[i]}) + \\frac \\lambda {1000} \\Sigma ||w^{[i]}||^2$\n",
        "\n",
        "이렇게 하나의 미니배치에 대한 비용을 계산\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN9xs6CBuimp"
      },
      "source": [
        "위에서 쓰인 $y^{pred[i]}$ 는 $X^{\\{t\\}}$를 기반으로 예측한 내용인고 \n",
        "\n",
        "$y^{true[i]}$는  $Y^{\\{t\\}}$"
      ]
    }
  ]
}