{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_prunning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQiSYc0uaG1UAlBnbavgWO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/audrb1999/ML-DL-Study/blob/main/Tensorflow/%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC/06.%20tensorflow_prunning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N86c9ogxK0Fc"
      },
      "source": [
        "이 자습서에서는 다음을 수행합니다.\n",
        "\n",
        "1. MNIST 용 tf.keras 모델을 처음부터 훈련합니다.\n",
        "가지 치기 API를 적용하여 모델을 미세 조정하고 정확도를 확인하십시오.\n",
        "\n",
        "2. 가지 치기에서 3 배 더 작은 TF 및 TFLite 모델을 만듭니다.\n",
        "\n",
        "3. 가지 치기와 훈련 후 양자화를 결합하여 10 배 더 작은 TFLite 모델을 만듭니다.\n",
        "\n",
        "4. TF에서 TFLite까지 정확도의 지속성을 확인하십시오.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjKEDNDjJ8GE",
        "outputId": "8a8d1666-1838-4b7e-b159-e57ab9552afd"
      },
      "source": [
        "!pip install -q tensorflow-model-optimization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51 kB 3.3 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 71 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 81 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 102 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 122 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 133 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 143 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 153 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 163 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 174 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 194 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 204 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 211 kB 3.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmN0dRsILL3r"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdgB9AqMK7bL",
        "outputId": "99fd6fc3-ccdc-4065-9ecf-76108265289d"
      },
      "source": [
        "# 데이터 불러오기\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# 0~1사이로 정규화 \n",
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "# 모델 구조 정의\n",
        "model = keras.Sequential([\n",
        "                          keras.layers.InputLayer(input_shape = (28, 28)),\n",
        "                          keras.layers.Reshape(target_shape = (28, 28, 1)),# shape을 바꿈\n",
        "                          keras.layers.Conv2D(filters = 12, kernel_size = (3, 3), activation = 'relu'),\n",
        "                          keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "                          keras.layers.Flatten(),\n",
        "                          keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# 모델 학습\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_images, train_labels, epochs = 4, validation_split=0.1\n",
        ")\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "1688/1688 [==============================] - 20s 11ms/step - loss: 0.2828 - accuracy: 0.9201 - val_loss: 0.1180 - val_accuracy: 0.9717\n",
            "Epoch 2/4\n",
            "1688/1688 [==============================] - 19s 11ms/step - loss: 0.1153 - accuracy: 0.9682 - val_loss: 0.0846 - val_accuracy: 0.9778\n",
            "Epoch 3/4\n",
            "1688/1688 [==============================] - 19s 11ms/step - loss: 0.0853 - accuracy: 0.9754 - val_loss: 0.0854 - val_accuracy: 0.9757\n",
            "Epoch 4/4\n",
            "1688/1688 [==============================] - 19s 11ms/step - loss: 0.0699 - accuracy: 0.9799 - val_loss: 0.0657 - val_accuracy: 0.9828\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f228215b990>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZezW5iyxUsqc",
        "outputId": "18fa0b55-fc3b-47a4-aa98-2a64606af037"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 12)        120       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 12)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2028)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20290     \n",
            "=================================================================\n",
            "Total params: 20,410\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MXaEV5vNo1L",
        "outputId": "5fbc0722-ddc1-43c6-8b6b-dd75b9983b57"
      },
      "source": [
        "_, base_acc = model.evaluate(test_images, test_labels, verbose = 0)\n",
        "\n",
        "print('base_acc', base_acc)\n",
        "\n",
        "#저장\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
        "\n",
        "print('saved baseline model to', keras_file)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_acc 0.9785000085830688\n",
            "saved baseline model to /tmp/tmp6qzs1e1k.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKWSXoZnOsWj",
        "outputId": "3ef99a83-31de-417a-84e9-b7adab6b0586"
      },
      "source": [
        "# 가지 치기로 모델 미세 조정\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "validation_split = 0.1 # 10%만 validation set으로 사용\n",
        "\n",
        "num_images = train_images.shape[0] * (1 - validation_split) # 학습 데이터 \n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs # 몇 step을 하는지\n",
        "\n",
        "# Pruning 정의\n",
        "\n",
        "pruning_params = {\n",
        "    'pruing_schedule' : tfmot.sparsity.keras.PolynomialDecay(initial_sparsity = 0.5,\n",
        "                                                             final_sparsity = 0.8,\n",
        "                                                             begin_step = 0,\n",
        "                                                             end_step = end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# compile를 다시 설정해줘야함\n",
        "\n",
        "model_for_pruning.compile(optimizer = 'adam',\n",
        "                          loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "                          metrics = ['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:2223: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_reshape_ (None, 28, 28, 1)         1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv2d_1 (None, 26, 26, 12)        230       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 13, 13, 12)        1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten_ (None, 2028)              1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_1  (None, 10)                40572     \n",
            "=================================================================\n",
            "Total params: 40,805\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 20,395\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5EANP1GTGg8",
        "outputId": "6e8c7860-fc3f-4df4-fd5f-ad5a89b2cb74"
      },
      "source": [
        "_, prune_acc = model_for_pruning.evaluate(\n",
        "   test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', base_acc) \n",
        "print('Pruned test accuracy:', prune_acc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.9785000085830688\n",
            "Pruned test accuracy: 0.9785000085830688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NQWnytNUm8s",
        "outputId": "fde64671-0424-46ec-da66-8eaeb422180d"
      },
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "model_for_pruning.fit(train_images, train_labels,\n",
        "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
        "                  callbacks=callbacks)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "422/422 [==============================] - 15s 32ms/step - loss: 0.0630 - accuracy: 0.9823 - val_loss: 0.0651 - val_accuracy: 0.9835\n",
            "Epoch 2/2\n",
            "422/422 [==============================] - 13s 32ms/step - loss: 0.0558 - accuracy: 0.9844 - val_loss: 0.0642 - val_accuracy: 0.9827\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2281e29c90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFPTZZv6VGuD",
        "outputId": "d5c3e174-d496-4bcb-e482-cd2871880f3d"
      },
      "source": [
        "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
        "   test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', base_acc) \n",
        "print('Pruned test accuracy:', prune_acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.9785000085830688\n",
            "Pruned test accuracy: 0.9785000085830688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD0Ae12jVwXV"
      },
      "source": [
        "# 가지 치기를 통해 3 배 더 작은 모델 생성\n",
        "\n",
        "정리의 압축 이점을 확인하려면 tfmot.sparsity.keras.strip_pruning 과 표준 압축 알고리즘 (예 : gzip을 통해) 적용이 필요합니다.\n",
        "\n",
        "- strip_pruning 은 학습 중에 만 필요로하는 모든 tf.Variable을 제거하기 때문에 필요합니다. 그렇지 않으면 추론 중에 모델 크기가 추가됩니다.\n",
        "\n",
        "\n",
        "- 직렬화 된 가중치 행렬은 가지 치기 전과 크기가 같으므로 표준 압축 알고리즘을 적용해야합니다. 그러나 가지 치기는 대부분의 가중치를 0으로 만들고 알고리즘이 모델을 추가로 압축하는 데 사용할 수있는 중복성을 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh4sTBr2VZ17",
        "outputId": "0e97e576-2225-4155-c714-2d9bd0d6e131"
      },
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)# 압축 알고리즘 사용\n",
        "\n",
        "# 저장\n",
        "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', pruned_keras_file)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved pruned Keras model to: /tmp/tmp4ke7rb82.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLo8Cm53V8oT",
        "outputId": "67605745-dc6d-4848-f21f-3e36c9b54065"
      },
      "source": [
        "# TFlite용 압축 가능한 모델을 만듭니다.\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)# TFLite로 변경할 주소\n",
        "pruned_tflite_model = converter.convert()# 변경\n",
        "\n",
        "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "  f.write(pruned_tflite_model)\n",
        "\n",
        "print('Saved pruned TFLite model to:', pruned_tflite_file)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /tmp/tmptdxnopda/assets\n",
            "Saved pruned TFLite model to: /tmp/tmpotxxox1z.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeJp9ANdWlEL"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHHOEOirWnWU",
        "outputId": "0e364d1e-eefb-4335-9722-aa62f3ea5b7b"
      },
      "source": [
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
        "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of gzipped baseline Keras model: 78247.00 bytes\n",
            "Size of gzipped pruned Keras model: 48479.00 bytes\n",
            "Size of gzipped pruned TFlite model: 47736.00 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRRajf4iWuvU"
      },
      "source": [
        "#가지 치기와 양자화를 결합하여 10 배 더 작은 모델 생성\n",
        "\n",
        "추가 이점을 위해 정리 된 모델에 사후 훈련 양자화를 적용 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXVQL0BoWwFT",
        "outputId": "f1ab5bfe-46a4-4071-ef7a-275ab81f39e3"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_and_pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
        "  f.write(quantized_and_pruned_tflite_model)\n",
        "\n",
        "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9ym5ul5r/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9ym5ul5r/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved quantized and pruned TFLite model to: /tmp/tmp0fg5b1i5.tflite\n",
            "Size of gzipped baseline Keras model: 78247.00 bytes\n",
            "Size of gzipped pruned and quantized TFlite model: 13722.00 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijamxc_XXTA1"
      },
      "source": [
        "# TF에서 TFLite까지 정확도 지속성 확인\n",
        "테스트 데이터 세트에서 TF Lite 모델을 평가하는 도우미 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYvAZ600XPic"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on ever y image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wre9wBUaXUvl"
      },
      "source": [
        "프루닝 및 양자화 모델을 평가하고 TensorFlow의 정확도가 TFLite 백엔드까지 유지되는지 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQfzYyLiXV18",
        "outputId": "024c2d31-9dea-40e9-8802-fcdbc6b890c4"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter)\n",
        "\n",
        "print('Pruned and quantized TFLite test_accuracy:', test_accuracy)\n",
        "print('Pruned TF test accuracy:', model_for_pruning_accuracy)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "Evaluated on 7000 results so far.\n",
            "Evaluated on 8000 results so far.\n",
            "Evaluated on 9000 results so far.\n",
            "\n",
            "\n",
            "Pruned and quantized TFLite test_accuracy: 0.9792\n",
            "Pruned TF test accuracy: 0.9793000221252441\n"
          ]
        }
      ]
    }
  ]
}